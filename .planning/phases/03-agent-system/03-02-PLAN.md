---
phase: 03-agent-system
plan: "02"
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - apps/server/src/agents/chief-of-staff.ts
  - apps/server/src/agents/agent-executor.ts
  - apps/server/src/agents/agent-tools.ts
  - apps/server/src/coaching/chat-route.ts
autonomous: true

must_haves:
  truths:
    - "When user has agents, chat uses ToolLoopAgent with needsApproval dispatch tools"
    - "Chief-of-staff responds directly for coaching questions, suggests agent only for task/deliverable requests"
    - "After user approves dispatch, specialist agent executes and returns result"
    - "When user has no agents, chat falls back to existing streamText behavior"
    - "Agent execution is recorded in agentExecutions table"
  artifacts:
    - path: "apps/server/src/agents/chief-of-staff.ts"
      provides: "buildChiefOfStaff factory that creates ToolLoopAgent from user's agents"
      exports: ["buildChiefOfStaff"]
    - path: "apps/server/src/agents/agent-executor.ts"
      provides: "executeSpecialistAgent that runs generateText with agent's system prompt"
      exports: ["executeSpecialistAgent"]
    - path: "apps/server/src/agents/agent-tools.ts"
      provides: "buildAgentTools that converts agent DB rows to needsApproval tool definitions"
      exports: ["buildAgentTools"]
    - path: "apps/server/src/coaching/chat-route.ts"
      provides: "Modified chat endpoint that conditionally uses ToolLoopAgent or streamText"
      contains: "createAgentUIStreamResponse"
  key_links:
    - from: "apps/server/src/coaching/chat-route.ts"
      to: "apps/server/src/agents/chief-of-staff.ts"
      via: "buildChiefOfStaff called when userAgents.length > 0"
      pattern: "buildChiefOfStaff"
    - from: "apps/server/src/agents/chief-of-staff.ts"
      to: "apps/server/src/agents/agent-tools.ts"
      via: "buildAgentTools provides tools for ToolLoopAgent"
      pattern: "buildAgentTools"
    - from: "apps/server/src/agents/agent-tools.ts"
      to: "apps/server/src/agents/agent-executor.ts"
      via: "tool execute function calls executeSpecialistAgent"
      pattern: "executeSpecialistAgent"
    - from: "apps/server/src/agents/agent-executor.ts"
      to: "apps/server/src/db/schema.ts"
      via: "records execution in agentExecutions table"
      pattern: "agentExecutions"
---

<objective>
Build the chief-of-staff ToolLoopAgent that dynamically creates needsApproval tools from the user's agents, and integrate it into the existing chat route.

Purpose: AGENT-03 (suggest-then-confirm routing) and AGENT-04 (agent results in chat) require the chief-of-staff orchestration layer. This replaces the simple streamText call with a ToolLoopAgent when agents are available, while preserving the existing coaching fallback.
Output: chief-of-staff.ts, agent-executor.ts, agent-tools.ts, and modified chat-route.ts.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-agent-system/03-RESEARCH.md
@.planning/phases/03-agent-system/03-01-SUMMARY.md
@apps/server/src/coaching/chat-route.ts
@apps/server/src/coaching/system-prompt.ts
@apps/server/src/coaching/mode-detector.ts
@apps/server/src/db/schema.ts
@apps/server/src/llm/providers.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Agent tools builder and specialist executor</name>
  <files>apps/server/src/agents/agent-tools.ts, apps/server/src/agents/agent-executor.ts</files>
  <action>
  1. Create `apps/server/src/agents/agent-executor.ts`:

  Import `generateText` from "ai", `getModel` from "../llm/providers", `db` from "../db", `agentExecutions` from "../db/schema", `eq` from "drizzle-orm".

  Export `async function executeSpecialistAgent(agent: { id: string; name: string; systemPrompt: string }, task: string, context: string | undefined, modelId: string, userId: string, conversationId: string | undefined)`:
  - Insert a row into agentExecutions with status "running", the agentId, userId, conversationId, and task
  - Call `generateText({ model: getModel(modelId), system: agent.systemPrompt, prompt: context ? \`Task: ${task}\n\nContext: ${context}\` : \`Task: ${task}\` })`
  - On success: update agentExecution row to status "completed", result = result.text, completedAt = new Date()
  - On error: update agentExecution row to status "failed", result = error message, completedAt = new Date(). Re-throw the error.
  - Return `{ agentName: agent.name, result: result.text, executionId: execution.id }`

  2. Create `apps/server/src/agents/agent-tools.ts`:

  Import `tool` from "ai", `z` from "zod", `executeSpecialistAgent` from "./agent-executor".

  Define the AgentRow type: `{ id: string; name: string; slug: string; description: string; systemPrompt: string }`.

  Export `function buildAgentTools(agents: AgentRow[], modelId: string, userId: string, conversationId: string | undefined)`:
  - Create an empty `Record<string, ReturnType<typeof tool>>` called `tools`
  - For each agent in the array, create a tool keyed as `dispatch_${agent.slug}`:
    - description: `Delegate to "${agent.name}": ${agent.description}`
    - inputSchema: z.object({ task: z.string().describe("The specific task to delegate"), context: z.string().optional().describe("Additional context from the conversation") })
    - needsApproval: true
    - execute: async ({ task, context }) => executeSpecialistAgent(agent, task, context, modelId, userId, conversationId)
  - Return the tools record
  </action>
  <verify>
  - TypeScript compiles: `cd apps/server && npx tsc --noEmit`
  </verify>
  <done>agent-executor.ts exports executeSpecialistAgent that runs generateText and records in agentExecutions. agent-tools.ts exports buildAgentTools that generates needsApproval tool definitions from agent DB rows.</done>
</task>

<task type="auto">
  <name>Task 2: Chief-of-staff ToolLoopAgent and chat route integration</name>
  <files>apps/server/src/agents/chief-of-staff.ts, apps/server/src/coaching/chat-route.ts</files>
  <action>
  1. Create `apps/server/src/agents/chief-of-staff.ts`:

  Import `ToolLoopAgent`, `stepCountIs` from "ai", `getModel` from "../llm/providers", `buildAgentTools` from "./agent-tools".

  Define `CHIEF_OF_STAFF_SYSTEM_PROMPT` -- use the system prompt from 03-RESEARCH.md verbatim. This prompt explicitly tells the LLM when to delegate vs respond directly.

  Export `function buildChiefOfStaff(params: { agents: AgentRow[], modelId: string, userId: string, conversationId: string | undefined, ragContext: string, userFactsSection: string, mode: string })`:
  - Build tools via `buildAgentTools(params.agents, params.modelId, params.userId, params.conversationId)`
  - Compose the full system prompt: CHIEF_OF_STAFF_SYSTEM_PROMPT + the existing mode instructions, user facts section, and RAG context section (same format as buildSystemPrompt produces, but inlined into the chief-of-staff instructions so the agent has full context)
  - Return `new ToolLoopAgent({ model: getModel(params.modelId), instructions: fullSystemPrompt, tools, stopWhen: stepCountIs(5) })`

  2. Modify `apps/server/src/coaching/chat-route.ts`:

  Add imports: `createAgentUIStreamResponse`, `ToolLoopAgent` from "ai"; `agents` table from "../db/schema"; `eq` from "drizzle-orm"; `buildChiefOfStaff` from "../agents/chief-of-staff"; `seedStarterAgents` from "../agents/templates".

  In the POST /api/chat handler, AFTER building the systemPrompt and BEFORE the current streamText call:

  a. Query user's agents: `const userAgents = await db.select().from(agents).where(eq(agents.userId, user.id))`

  b. **If userAgents.length > 0** (user has agents -- agent mode):
     - Build the chief-of-staff: `const chiefOfStaff = buildChiefOfStaff({ agents: userAgents, modelId, userId: user.id, conversationId: chatId, ragContext: contextSection, userFactsSection: factsSection, mode: effectiveMode })`
     - Return `createAgentUIStreamResponse({ agent: chiefOfStaff, uiMessages: messages, onFinish: async ({ messages: updatedMessages }) => { /* same persistence + fact extraction logic as existing onFinish */ } })`
     - Set the X-Chat-Id header on the response before returning (use c.header() or pass headers option if createAgentUIStreamResponse supports it -- if not, wrap the response with the header)

  c. **Else** (no agents -- fallback to existing behavior):
     - Keep the existing streamText + toUIMessageStreamResponse code path exactly as-is

  Important: The existing mode detection, RAG retrieval, fact loading, and onFinish persistence logic must remain for BOTH paths. The chief-of-staff path just changes how the LLM is invoked (ToolLoopAgent instead of streamText) and how the response is returned (createAgentUIStreamResponse instead of toUIMessageStreamResponse).

  Important: Do NOT use `toolChoice: "required"` -- use `"auto"` (or omit, which defaults to auto). This prevents the over-routing pitfall where every message triggers an agent dispatch.
  </action>
  <verify>
  - TypeScript compiles: `cd apps/server && npx tsc --noEmit`
  - Server starts without errors
  - With no agents in DB for a user, the existing chat behavior works unchanged (test by sending a message)
  </verify>
  <done>Chief-of-staff ToolLoopAgent created from user's agents with needsApproval tools. Chat route branches: ToolLoopAgent + createAgentUIStreamResponse when agents exist, existing streamText path when no agents. Conversation persistence and fact extraction work in both paths.</done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes in apps/server
- Server starts and /health returns 200
- Existing chat (for user with no agents) continues to stream responses as before
- When a user has agents (from Plan 01 seeding), the chat route constructs a ToolLoopAgent
</verification>

<success_criteria>
- chief-of-staff.ts: buildChiefOfStaff creates a ToolLoopAgent with dynamic needsApproval tools from agent rows
- agent-executor.ts: executeSpecialistAgent runs generateText with agent systemPrompt and records execution
- agent-tools.ts: buildAgentTools converts DB rows to AI SDK tool definitions
- chat-route.ts: conditionally uses ToolLoopAgent or streamText based on user's agent count
- No regressions: chat without agents works identically to Phase 2
</success_criteria>

<output>
After completion, create `.planning/phases/03-agent-system/03-02-SUMMARY.md`
</output>
