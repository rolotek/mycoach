---
phase: 06-api-key-management
plan: 03
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - apps/server/src/coaching/chat-route.ts
  - apps/server/src/agents/agent-executor.ts
  - apps/server/src/agents/chief-of-staff.ts
  - apps/server/src/agents/agent-tools.ts
autonomous: true

must_haves:
  truths:
    - "Chat route resolves model using user's settings and API key (not just env var)"
    - "Token usage is recorded in tokenUsage table after every chat response"
    - "Agent execution uses per-user model resolution"
    - "Budget is checked before processing chat requests"
    - "Agent-level preferredModel is respected when dispatching to specialist agents"
    - "Background operations (fact extraction) continue using system keys"
  artifacts:
    - path: "apps/server/src/coaching/chat-route.ts"
      provides: "Per-user model resolution, token tracking via onFinish, budget check"
      contains: "resolveUserModel"
    - path: "apps/server/src/agents/agent-executor.ts"
      provides: "Agent execution with per-user model and token tracking"
      contains: "resolveUserModel"
    - path: "apps/server/src/agents/chief-of-staff.ts"
      provides: "Chief of staff using resolved model instance"
      contains: "model:"
    - path: "apps/server/src/agents/agent-tools.ts"
      provides: "Agent tools passing resolved model context"
      contains: "resolveUserModel"
  key_links:
    - from: "apps/server/src/coaching/chat-route.ts"
      to: "apps/server/src/llm/providers.ts"
      via: "resolveUserModel(userId)"
      pattern: "resolveUserModel"
    - from: "apps/server/src/coaching/chat-route.ts"
      to: "apps/server/src/db/schema.ts"
      via: "tokenUsage insert in onFinish"
      pattern: "tokenUsage"
    - from: "apps/server/src/agents/agent-executor.ts"
      to: "apps/server/src/llm/pricing.ts"
      via: "calculateCostCents in onFinish"
      pattern: "calculateCostCents"
    - from: "apps/server/src/coaching/chat-route.ts"
      to: "apps/server/src/db/schema.ts"
      via: "budget check query on tokenUsage + userSettings"
      pattern: "monthlyBudgetCents"
---

<objective>
Wire the chat route, agent executor, chief-of-staff, and agent tools to use per-user model resolution and track token usage. Add budget enforcement before processing requests.

Purpose: This is the core integration that makes user API keys and model selection actually work. Without this, the stored keys are unused and usage is untracked.
Output: Chat and agent paths use per-user models, track tokens, and enforce budgets.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-api-key-management-usage-tracking-users-can-set-individual-api-keys-for-anthropic-openai-select-models-track-token-usage-and-monitor-spending-against-budgets-using-provider-billing-apis/06-01-SUMMARY.md
@apps/server/src/coaching/chat-route.ts
@apps/server/src/agents/agent-executor.ts
@apps/server/src/agents/chief-of-staff.ts
@apps/server/src/agents/agent-tools.ts
@apps/server/src/llm/providers.ts
@apps/server/src/llm/pricing.ts
@apps/server/src/db/schema.ts
@.planning/phases/06-api-key-management-usage-tracking-users-can-set-individual-api-keys-for-anthropic-openai-select-models-track-token-usage-and-monitor-spending-against-budgets-using-provider-billing-apis/06-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate per-user model resolution, token tracking, and budget check into chat route</name>
  <files>apps/server/src/coaching/chat-route.ts</files>
  <action>
Modify `apps/server/src/coaching/chat-route.ts`:

1. Replace `import { getModel } from "../llm/providers"` with `import { getModel, resolveUserModel } from "../llm/providers"`
2. Import `tokenUsage, userSettings` from `../db/schema` (add to existing import)
3. Import `calculateCostCents` from `../llm/pricing`
4. Import `gte, sql` from `drizzle-orm` (add to existing import if not present)

5. Add a `checkBudget` helper function inside the file:
   ```
   async function checkBudget(userId: string): Promise<{ allowed: boolean; remaining: number }> {
     const [settings] = await db.select().from(userSettings).where(eq(userSettings.userId, userId));
     if (!settings?.monthlyBudgetCents) return { allowed: true, remaining: Infinity };
     const startOfMonth = new Date();
     startOfMonth.setDate(1);
     startOfMonth.setHours(0, 0, 0, 0);
     const [result] = await db
       .select({ total: sql<number>`COALESCE(SUM(${tokenUsage.estimatedCostCents}), 0)` })
       .from(tokenUsage)
       .where(and(eq(tokenUsage.userId, userId), gte(tokenUsage.createdAt, startOfMonth)));
     const spent = result?.total ?? 0;
     const remaining = settings.monthlyBudgetCents - spent;
     return { allowed: remaining > 0, remaining };
   }
   ```

6. Add a `trackUsage` helper function:
   ```
   async function trackUsage(params: {
     userId: string;
     conversationId: string | null;
     provider: string;
     model: string;
     inputTokens: number;
     outputTokens: number;
   }) {
     await db.insert(tokenUsage).values({
       userId: params.userId,
       conversationId: params.conversationId,
       provider: params.provider,
       model: params.model,
       inputTokens: params.inputTokens,
       outputTokens: params.outputTokens,
       estimatedCostCents: calculateCostCents(params.model, params.inputTokens, params.outputTokens),
     });
   }
   ```

7. In the POST /api/chat handler, after getting the user, add budget check:
   ```
   const budgetCheck = await checkBudget(user.id);
   if (!budgetCheck.allowed) {
     return c.json({ error: "Monthly budget exceeded. Update your budget in Settings to continue." }, 429);
   }
   ```

8. Replace the hardcoded modelId resolution:
   - OLD: `const modelId = process.env.COACH_CHAT_MODEL ?? \`ollama:\${process.env.OLLAMA_MODEL || "llama3.1"}\`;`
   - NEW: `const resolved = await resolveUserModel(user.id);`
   - Use `resolved.model` wherever `getModel(modelId)` was used
   - Use `resolved.modelName` for the modelId string in function calls that need it
   - Use `resolved.provider` for provider identification
   - Keep the full prefixed format (`${resolved.provider}:${resolved.modelName}`) for places that pass modelId to chief-of-staff/agent-tools (since those will be updated in Task 2 to accept model instances)

9. In the agent path (when `userAgents.length > 0`):
   - Pass `resolved.model` to `buildChiefOfStaff` instead of a modelId string (requires Task 2 changes, but prepare the call site here)
   - For now, keep passing the prefixed modelId string since chief-of-staff still expects it; Task 2 will update both sides
   - Actually: pass `{ model: resolved.model, modelId: \`\${resolved.provider}:\${resolved.modelName}\`, provider: resolved.provider, modelName: resolved.modelName }` as a `resolvedModel` param

10. In the streamText path (no agents), replace `model: getModel(modelId)` with `model: resolved.model`

11. In BOTH onFinish callbacks (agent path and streamText path), add token usage tracking:
    - For the streamText path, the `onFinish` callback receives `{ messages, totalUsage }` via `toUIMessageStreamResponse`. Actually, the `toUIMessageStreamResponse` onFinish does not provide totalUsage. Instead, capture it from the `streamText` result:
      - The `streamText` call returns a `result` object. Access `result.totalUsage` (a promise for streaming) -- but since we are in `onFinish` we need a different approach.
      - Better approach: Use the `onFinish` option DIRECTLY on `streamText()` (not on `toUIMessageStreamResponse`), which provides `{ totalUsage }`:
      ```
      const result = streamText({
        model: resolved.model,
        system: systemPrompt,
        messages: modelMessages,
        ...taskTools,
        onFinish: async ({ totalUsage }) => {
          trackUsage({
            userId: user.id,
            conversationId: chatId,
            provider: resolved.provider,
            model: resolved.modelName,
            inputTokens: totalUsage.inputTokens ?? 0,
            outputTokens: totalUsage.outputTokens ?? 0,
          }).catch((err) => console.error("Usage tracking failed:", err));
        },
      });
      ```
      Then use `result.toUIMessageStreamResponse({ ... onFinish for persistence ... })` for message persistence.
    - Note: the existing `extractFacts` and conversation persistence stay in `toUIMessageStreamResponse.onFinish`. Token tracking goes in `streamText.onFinish` because that's where `totalUsage` is available.
    - For the agent path (createAgentUIStream), token tracking is harder because the agent makes multiple LLM calls internally. The agent-executor will handle its own tracking (Task 2). The chief-of-staff response tracking can be deferred -- the main token cost is in agent execution.

12. Fire-and-forget the trackUsage call: `trackUsage(...).catch((err) => console.error("Usage tracking failed:", err))` -- do NOT await it. This follows the existing pattern used for `extractFacts`.
  </action>
  <verify>
Run `cd /Users/allenwong/Workspace/mycoach && npm run type-check` -- should pass.
  </verify>
  <done>Chat route resolves model via user settings with key fallback. Budget is checked before processing. Token usage is tracked in onFinish. streamText uses resolved.model. Fact extraction still uses system keys (unchanged).</done>
</task>

<task type="auto">
  <name>Task 2: Update agent executor, chief-of-staff, and agent tools for per-user model resolution</name>
  <files>apps/server/src/agents/agent-executor.ts, apps/server/src/agents/chief-of-staff.ts, apps/server/src/agents/agent-tools.ts</files>
  <action>
**agent-executor.ts:**
1. Import `resolveUserModel` from `../llm/providers` (replace `getModel` import)
2. Import `tokenUsage` from `../db/schema`, `calculateCostCents` from `../llm/pricing`
3. Change `executeSpecialistAgent` signature: replace `modelId: string` parameter with `modelId: string, agentPreferredModel?: string | null`
4. At the start of the function, resolve the model:
   ```
   const resolved = await resolveUserModel(userId, agentPreferredModel);
   ```
   BUT also keep the `modelId` parameter as a fallback identifier for the prefixed format.
   Actually, simplify: the `modelId` param is the user's default prefixed model. The `agentPreferredModel` is the agent's optional override. We want:
   - If agent has preferredModel set, use that (it's already in "provider:model" format)
   - Otherwise use the modelId passed in (user's default)

   Better approach: Accept a pre-resolved model instance instead of a modelId string:
   - Change signature to accept `model: LanguageModel` (already resolved by the caller) plus `provider: string` and `modelName: string` for tracking
   - Import `LanguageModel` from `ai`
   - Replace `getModel(modelId)` with `model` in the `generateText` call

   Actually, the cleanest approach given the agent-level model override: keep `modelId` as a string but add `agentPreferredModel?: string | null`. Then resolve inside:
   ```
   const effectiveModelId = agentPreferredModel || modelId;
   const resolved = await resolveUserModel(userId, effectiveModelId !== modelId ? agentPreferredModel : undefined);
   ```
   No, even simpler: just call `resolveUserModel(userId, agentPreferredModel)`. This will use agentPreferredModel if set, else user's default, else env var. The `modelId` parameter is no longer needed.

   Final approach:
   - Remove the `modelId` parameter from the signature
   - Add `agentPreferredModel?: string | null` parameter
   - Call `const resolved = await resolveUserModel(userId, agentPreferredModel);`
   - Use `resolved.model` in `generateText`

5. In the `generateText` call, add token tracking:
   ```
   const genResult = await generateText({
     model: resolved.model,
     system: agent.systemPrompt,
     prompt: context ? `Task: ${task}\n\nContext: ${context}` : `Task: ${task}`,
   });

   // Track usage (fire-and-forget)
   db.insert(tokenUsage).values({
     userId,
     conversationId: conversationId ?? null,
     provider: resolved.provider,
     model: resolved.modelName,
     inputTokens: genResult.totalUsage.inputTokens ?? 0,
     outputTokens: genResult.totalUsage.outputTokens ?? 0,
     estimatedCostCents: calculateCostCents(
       resolved.modelName,
       genResult.totalUsage.inputTokens ?? 0,
       genResult.totalUsage.outputTokens ?? 0
     ),
   }).catch((err) => console.error("Agent usage tracking failed:", err));
   ```

6. Update the return to still use `genResult.text` for the result.

**agent-tools.ts:**
1. Update `buildAgentTools` signature: remove `modelId: string` parameter, add `userId` is already there
2. Add `agentPreferredModels?: Record<string, string | null>` parameter -- a map from agent.id to agent.preferredModel
3. In the `execute` callback for each agent tool, pass the agent's preferredModel:
   ```
   execute: async ({ task, context }) =>
     executeSpecialistAgent(
       { id: agent.id, name: agent.name, systemPrompt: agent.systemPrompt },
       task,
       context,
       userId,
       conversationId,
       agentPreferredModels?.[agent.id] ?? null
     ),
   ```
4. Remove the `modelId` from the executeSpecialistAgent call since it no longer takes it.

**chief-of-staff.ts:**
1. Update `buildChiefOfStaff` params:
   - Remove `modelId: string`
   - Add `model: LanguageModel` (import from `ai`)
   - Add `agentPreferredModels: Record<string, string | null>`
2. Update `buildAgentTools` call:
   - Remove `params.modelId`
   - Pass `params.agentPreferredModels`
3. Update `new ToolLoopAgent({ model: params.model, ... })` -- use the pre-resolved model instance directly

**chat-route.ts (adjust the calls made in Task 1):**
- Build an `agentPreferredModels` map from the loaded `userAgents`:
  ```
  const agentPreferredModels: Record<string, string | null> = {};
  for (const agent of userAgents) {
    agentPreferredModels[agent.id] = (agent as any).preferredModel ?? null;
  }
  ```
  (Note: the agents select already includes all columns, so preferredModel should be available after 06-01 schema update)
- Pass `model: resolved.model` and `agentPreferredModels` to `buildChiefOfStaff` instead of `modelId`
- Pass `agentPreferredModels` to `resolveApprovedDispatchTools` -- check if that function also needs updating. If `resolveApprovedDispatchTools` uses modelId, update it similarly.

Check `resolve-approved-dispatch.ts` and update if it passes modelId to executeSpecialistAgent. If so, update its signature to match the new approach (remove modelId, add agentPreferredModels map or resolve per-agent).
  </action>
  <verify>
Run `cd /Users/allenwong/Workspace/mycoach && npm run type-check` -- should pass.
  </verify>
  <done>Agent executor resolves models per-user with agent-level override. Token usage tracked for every agent execution. Chief-of-staff uses pre-resolved model instance. Agent tools pass per-agent preferredModel. All internal LLM calls except background operations (fact extraction, prompt evolution) use per-user keys.</done>
</task>

</tasks>

<verification>
- `npm run type-check` passes
- Chat route uses resolveUserModel instead of hardcoded env var model
- Budget check returns 429 when exceeded
- tokenUsage inserts happen in onFinish (fire-and-forget pattern)
- Agent executor tracks its own token usage
- Background ops (extractFacts, prompt evolver) still use system keys (unchanged)
</verification>

<success_criteria>
Every interactive LLM call (chat, agent execution) resolves the user's preferred model and API key, tracks token usage, and respects budget limits. For cloud providers (Anthropic, OpenAI, Google) the user must set their own API key in Settingsâ€”no env fallback; missing key returns a clear error (ApiKeyRequiredError, 400 from chat route). Background operations remain on system keys.
</success_criteria>

<output>
After completion, create `.planning/phases/06-api-key-management-usage-tracking-users-can-set-individual-api-keys-for-anthropic-openai-select-models-track-token-usage-and-monitor-spending-against-budgets-using-provider-billing-apis/06-03-SUMMARY.md`
</output>
